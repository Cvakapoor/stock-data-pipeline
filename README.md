# ğŸ“ˆ Real-Time Stock Volatility Monitoring Pipeline

This project implements a real-time stock analytics pipeline that streams live and simulated stock prices, computes volatility metrics, generates alerts, and visualizes data. It uses a modern stack including Kafka, PostgreSQL, MinIO, Airflow, and Streamlit.

---

## ğŸš€ Features

- â° **Scheduled Data Ingestion**: Fetches stock price data from an external API every minute using Apache Airflow.
- ğŸ§® **Volatility Computation**: Calculates rolling volatility, returns, and Sharpe ratio using pandas.
- âš ï¸ **Anomaly Detection**: Detects significant volatility spikes and logs risk alerts.
- ğŸ—ƒï¸ **Storage in PostgreSQL**: All data and alerts are stored in a PostgreSQL database for durability and queryability.
- ğŸ“Š **Streamlit Dashboard**: Interactive UI to visualize metrics and track recent alerts.

---

## ğŸ› ï¸ Technologies Used

- **Apache Airflow** â€“ Workflow orchestration and scheduling
- **PostgreSQL** â€“ Relational database for storing price, volatility, and alert data
- **Streamlit** â€“ Web dashboard for data visualization
- **Docker & Docker Compose** â€“ Containerization and orchestration
- **Pandas / Plotly** â€“ Data processing and charting
- **psycopg2** â€“ PostgreSQL database connector for Python

---
```mermaid
graph LR
    A[Finnhub API / Data Sim] --> B[Kafka Producer]
    B --> C[Kafka Broker]
    C --> D[Kafka Consumer]
    D --> E[MinIO (Raw CSV Storage)]
    E --> F[Airflow DAGs (ETL & Scheduler)]
    F --> G[PostgreSQL (Processed Data)]
    G --> H[Volatility & Alert Scripts]
    G --> I[Streamlit Dashboard]
```


## ğŸ§± Architecture Overview

```plaintext
+------------------------------+
|  Finnhub API / Data Sim      |
+--------------+---------------+
               |
               â–¼
      +--------+--------+
      |   Kafka Producer |
      +--------+--------+
               |
               â–¼
        +------+------+
        | Kafka Broker |
        +------+------+
               |
               â–¼
      +--------+--------+
      |  Kafka Consumer  |
      +--------+--------+
               |
               â–¼
        +------+------+
        |   MinIO (Raw  |
        |   CSV Storage)|
        +------+------+
               |
               â–¼
      +--------+--------+
      | Airflow DAGs     |
      | (ETL & Scheduler)|
      +--------+--------+
               |
               â–¼
       +-------+--------+
       |   PostgreSQL   |
       | (Processed DB) |
       +---+--------+---+
           |        |
           â–¼        â–¼
+----------------+ +-----------------------+
| Volatility &   | |  Streamlit Dashboard |
| Alert Scripts  | |   (Interactive UI)   |
+----------------+ +-----------------------+
```
---

## âš™ï¸ Setup Instructions

- â° **Clone the Repository**
<pre> git clone https://github.com/cvakapoor/stock-volatility-pipeline.git</pre>
<pre> cd stock-volatility-pipeline</pre>
  
- â° **Run PostgreSQL and Airflow**

You can either:

1. Run PostgreSQL and Airflow in separate containers manually, or
2. Integrate both into a unified `docker-compose.yml` setup.

Make sure to update your `docker-compose.yml` accordingly, and drop/recreate the Docker network if needed.

ğŸ“Œ **Note:** Ensure that the Airflow and PostgreSQL services are connected via the same Docker network.

---

## ğŸ“Š Streamlit Dashboard

The project includes an interactive **Streamlit dashboard** (streamlit_app.py) to visualize real-time stock metrics, including:
- ğŸ“ˆ **Price Trends** â€” Line chart of price over time
- ğŸŒªï¸ **Volatility Metrics** â€” Visuals for volatility and Sharpe ratio
- âš ï¸ **Recent Alerts** â€” Table of triggered alert messages
  
